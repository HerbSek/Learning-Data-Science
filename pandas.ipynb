{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2723e4f0-56b4-4516-893f-a10738b55485",
   "metadata": {},
   "source": [
    "## Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d4d574-dc5e-41f2-ad50-e8586e4b697c",
   "metadata": {},
   "source": [
    "### Three fundermental Pandas data Structures \n",
    "\n",
    "#### Series as a generalized Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dda9fb6-6c5c-4a93-ae23-10635ee8b4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.25\n",
      "1    0.50\n",
      "2    0.75\n",
      "3    1.00\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.25, 0.5 , 0.75, 1.  ]),\n",
       " RangeIndex(start=0, stop=4, step=1),\n",
       " np.float64(0.5))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.Series([0.25,0.5,0.75,1.0])\n",
    "print(data)\n",
    "data.values, data.index, data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "966ba0d0-8910-4d62-91a5-127ae24b5f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(apple      0.25\n",
       " banana     0.50\n",
       " cabbage    0.75\n",
       " donuts     1.00\n",
       " dtype: float64,\n",
       " 2    0\n",
       " 3    2\n",
       " 4    3\n",
       " 5    4\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0], index=['apple','banana','cabbage','donuts'])\n",
    "data2 = pd.Series([0,2,3,4], index=[2,3,4,5])\n",
    "data , data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc730e5c-f754-4eb8-9bff-3b256f86db68",
   "metadata": {},
   "source": [
    "#### Series as a specialized dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8874450-e9bc-4347-aa87-542a0a239e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California    38332521\n",
       "Texas         26448193\n",
       "New York      19651127\n",
       "Florida       19552860\n",
       "Illinois      12882135\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "population_dict = {\n",
    "'California': 38332521,\n",
    " 'Texas': 26448193,\n",
    " 'New York': 19651127,\n",
    " 'Florida': 19552860,\n",
    " 'Illinois': 12882135\n",
    "}\n",
    "\n",
    "population = pd.Series(population_dict)\n",
    "population\n",
    "# population['California':'Florida'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94138dec-8ef9-43f6-bc52-b1e1d8e4f4ed",
   "metadata": {},
   "source": [
    "### The Pandas DataFrame Object "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bcfe83-1ffb-4db2-94a2-113d05efbbc4",
   "metadata": {},
   "source": [
    "#### DataFrame as a generalized NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af1208c3-977b-467e-82bf-51b0b61597ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Area</th>\n",
       "      <th>Population Density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>38332521</td>\n",
       "      <td>423967</td>\n",
       "      <td>90.413926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>26448193</td>\n",
       "      <td>695662</td>\n",
       "      <td>38.018740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>19651127</td>\n",
       "      <td>141297</td>\n",
       "      <td>139.076746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>19552860</td>\n",
       "      <td>170312</td>\n",
       "      <td>114.806121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>12882135</td>\n",
       "      <td>149995</td>\n",
       "      <td>85.883763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Population    Area  Population Density\n",
       "California    38332521  423967           90.413926\n",
       "Texas         26448193  695662           38.018740\n",
       "New York      19651127  141297          139.076746\n",
       "Florida       19552860  170312          114.806121\n",
       "Illinois      12882135  149995           85.883763"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "population_dict = {\n",
    "'California': 38332521,\n",
    " 'Texas': 26448193,\n",
    " 'New York': 19651127,\n",
    " 'Florida': 19552860,\n",
    " 'Illinois': 12882135\n",
    "}\n",
    "\n",
    "population = pd.Series(population_dict)\n",
    "population\n",
    "area_dict = {'California': 423967, 'Texas': 695662, 'New York': 141297,'Florida': 170312, 'Illinois': 149995}\n",
    "area = pd.Series(area_dict)\n",
    "\n",
    "states = pd.DataFrame({'Population':population, 'Area':area})\n",
    "states['Population Density'] = states['Population'] / states['Area']\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a3caf81-ecb8-4ef5-a93c-cb11a9c44424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            population    area\n",
      "California    38332521  423967\n",
      "Texas         26448193  695662\n",
      "New York      19651127  141297\n",
      "Florida       19552860  170312\n",
      "Illinois      12882135  149995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "California    423967\n",
       "Texas         695662\n",
       "New York      141297\n",
       "Florida       170312\n",
       "Illinois      149995\n",
       "Name: area, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "population_dict = {'California': 38332521,\n",
    "'Texas': 26448193,\n",
    "'New York': 19651127,\n",
    "'Florida': 19552860,\n",
    "'Illinois': 12882135}\n",
    "\n",
    "area_dict = {'California': 423967, 'Texas'Florida       170312\n",
    ": 695662, 'New York': 141297,'Florida': 170312, 'Illinois': 149995}\n",
    "\n",
    "population = pd.Series(population_dict)\n",
    "area = pd.Series(area_dict)\n",
    "\n",
    "states_dict = {'population': population, 'area': area }\n",
    "states = pd.DataFrame(states_dict)\n",
    "\n",
    "print(states)\n",
    "states['area']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdf9a5a-466a-45d5-934b-77844cae20ee",
   "metadata": {},
   "source": [
    "#### DataFrame as a specialized Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b46a648-8ab2-4e59-949d-04ce5d265d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.) (0, 0.) (0, 0.)]\n",
      "   A    B\n",
      "0  0  0.0\n",
      "1  0  0.0\n",
      "2  0  0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dtype = [('A','i8'),('B','f8')]\n",
    "A = np.zeros(3, dtype = dtype)\n",
    "print(A)\n",
    "Adata = pd.DataFrame(A)\n",
    "print(Adata)\n",
    "# Aindex = pd.Index(A)\n",
    "# Aindex[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93aa863d-0875-479c-abc0-389b5fac8ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([2, 5, 11], dtype='int64')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = pd.Index([2, 3, 5, 7, 11])\n",
    "ind[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa40d0-24bd-47d5-92a7-d5b50ebb8183",
   "metadata": {},
   "source": [
    "#### Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07a42a98-b263-4928-8b09-71875e2999e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Presidents</th>\n",
       "      <th>Heights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Adams</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thomas Jefferson</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Madison</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>James Monroe</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>John Quincy Adams</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Andrew Jackson</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Martin Van Buren</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>William Henry Harrison</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>John Tyler</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Zachary Taylor</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Millard Fillmore</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Franklin Pierce</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>James Buchanan</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Andrew Johnson</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ulysses S. Grant</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rutherford B. Hayes</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>James A. Garfield</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chester A. Arthur</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Presidents Heights\n",
       "1        George Washington     189\n",
       "2               John Adams     170\n",
       "3         Thomas Jefferson     189\n",
       "4            James Madison     180\n",
       "5             James Monroe     175\n",
       "6        John Quincy Adams     160\n",
       "7           Andrew Jackson     185\n",
       "8         Martin Van Buren     170\n",
       "9   William Henry Harrison     165\n",
       "10              John Tyler     168\n",
       "11          Zachary Taylor     172\n",
       "12        Millard Fillmore     178\n",
       "13         Franklin Pierce     182\n",
       "14          James Buchanan     174\n",
       "15         Abraham Lincoln     190\n",
       "16          Andrew Johnson     177\n",
       "17        Ulysses S. Grant     188\n",
       "18     Rutherford B. Hayes     166\n",
       "19       James A. Garfield     180\n",
       "20       Chester A. Arthur     171"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file = pd.read_csv('president.csv')\n",
    "data = np.array(file)\n",
    "data[:,0], data[:,1], data[:,2]\n",
    "# np.hsplit(data,3)[0] ~ data[:,0]\n",
    "# Now we assign them using DataFrame and Series from the pandas Library\n",
    "\n",
    "presidents = pd.Series(data[:,1], index=data[:,0])\n",
    "heights = pd.Series(data[:,2], index=data[:,0])\n",
    "# info_dict = {'Presidents': presidents, 'heights':heights}\n",
    "# info = pd.DataFrame(info_dict) \n",
    "\n",
    "info = pd.DataFrame(data[:,1:], columns=['Presidents','Heights'] , index=data[:,0])\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96925d06-7781-4942-b83b-ca5ed10be0fe",
   "metadata": {},
   "source": [
    "### Data Selection and Indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "170f8b54-ef9f-40a8-b83c-3f52503adb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0.25\n",
       "b    0.50\n",
       "c    0.75\n",
       "d    1.00\n",
       "e    0.70\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.Series([0.25,0.5,0.75,1.0], index = ['a','b','c','d'])\n",
    "data['e'] =0.7 \n",
    "data\n",
    "# data.keys()\n",
    "# list(data.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a664e662-dbbe-4890-aab9-45283605ed93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.25)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy \n",
    "import pandas as pd\n",
    "data = pd.Series([0.25,0.5,0.75,1.0], index = ['a','b','c','d'])\n",
    "data[(data > 0.3) & (data < 0.8)].sum()\n",
    "# data.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475c6d5-d9e0-44e9-bd31-3f6fb1d946cf",
   "metadata": {},
   "source": [
    "### Indexers (loc,iloc and ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e9a4829-98d3-4dc4-abeb-3ae1faff6d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    a\n",
      "3    b\n",
      "dtype: object\n",
      "\n",
      "1    a\n",
      "3    b\n",
      "5    c\n",
      "dtype: object\n",
      "1    a\n",
      "3    b\n",
      "5    c\n",
      "7    d\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series(['a', 'b', 'c', 'd'], index=[1, 3, 5,7])\n",
    "data\n",
    "print(data.loc[:4])\n",
    "print()\n",
    "print(data.iloc[:3])\n",
    "print(data[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a1a1c64-e1e4-45e7-ae4b-018b85f4faa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B  C  D\n",
       "1   5  11  8  9\n",
       "2  11   5  0  0\n",
       "3   1   7  6  9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1)\n",
    "my_array = np.random.randint(12, size=12).reshape((3,4))\n",
    "my_array = pd.DataFrame(my_array, columns=['A', 'B', 'C', 'D'] )\n",
    "my_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e088ea-e2ab-48d8-9228-7f44419e00d9",
   "metadata": {},
   "source": [
    "#### Exercise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da40ce98-4567-496d-9936-cbe4f8443ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Meal Name</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corba</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Soup</td>\n",
       "      <td>Pick through your lentils for any foreign debr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tamiya</td>\n",
       "      <td>Egyptian</td>\n",
       "      <td>No Tag</td>\n",
       "      <td>oak the beans in water to cover overnight.Drai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasagne</td>\n",
       "      <td>Italian</td>\n",
       "      <td>No Tag</td>\n",
       "      <td>Heat the oil in a large saucepan. Use kitchen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kafteji</td>\n",
       "      <td>Tunisian</td>\n",
       "      <td>No Tag</td>\n",
       "      <td>Peel potatoes and cut into 5cm cubes.Pour 1-2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dal fry</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Curry,Vegetarian,Cake</td>\n",
       "      <td>Wash and soak toor dal in approx. 3 cups of wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Big Mac</td>\n",
       "      <td>American</td>\n",
       "      <td>No Tag</td>\n",
       "      <td>For the Big Mac sauce, combine all the ingredi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Koshari</td>\n",
       "      <td>Egyptian</td>\n",
       "      <td>No Tag</td>\n",
       "      <td>Cook the lentils. Bring lentils and 4 cups of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kapsalon</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Snack</td>\n",
       "      <td>Cut the meat into strips. Heat oil in a pan an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stamppot</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Savory,Breakfast</td>\n",
       "      <td>Wash and peel the potatoes and cut into simila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Flamiche</td>\n",
       "      <td>French</td>\n",
       "      <td>Tart</td>\n",
       "      <td>For the pastry, sift the flour and salt into t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Moussaka</td>\n",
       "      <td>Greek</td>\n",
       "      <td>No Tag</td>\n",
       "      <td>Heat the grill to high. Brown the beef in a de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pancakes</td>\n",
       "      <td>American</td>\n",
       "      <td>Breakfast,Desert,Sweet,Fruity</td>\n",
       "      <td>Put the flour, eggs, milk, 1 tbsp oil and a pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Shawarma</td>\n",
       "      <td>Egyptian</td>\n",
       "      <td>No Tag</td>\n",
       "      <td>Combine the marinade ingredients in a large zi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Shakshuka</td>\n",
       "      <td>Egyptian</td>\n",
       "      <td>Egg,Brunch,Breakfast</td>\n",
       "      <td>Heat the oil in a frying pan that has a lid, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Yaki Udon</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>LowCalorie</td>\n",
       "      <td>Boil some water in a large saucepan. Add 250ml...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ribollita</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Put 2 tablespoons of the oil in a large pot ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sugar Pie</td>\n",
       "      <td>Canadian</td>\n",
       "      <td>Pie,Desert</td>\n",
       "      <td>Preheat oven to 350 degrees F (175 degrees C)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rock Cakes</td>\n",
       "      <td>British</td>\n",
       "      <td>Baking,Cake</td>\n",
       "      <td>Preheat oven to 180C/350F/Gas 4 and line a bak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pad See Ew</td>\n",
       "      <td>Thai</td>\n",
       "      <td>Pasta</td>\n",
       "      <td>Mix Sauce in small bowl.Mince garlic into wok ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rappie Pie</td>\n",
       "      <td>Canadian</td>\n",
       "      <td>Pie</td>\n",
       "      <td>Preheat oven to 400 degrees F (200 degrees C)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ma Po Tofu</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>No Tag</td>\n",
       "      <td>Add a small pinch of salt and sesame oil to mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Coq au vin</td>\n",
       "      <td>French</td>\n",
       "      <td>No Tag</td>\n",
       "      <td>Heat 1 tbsp of the oil in a large, heavy-based...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Nasi lemak</td>\n",
       "      <td>Malaysian</td>\n",
       "      <td>No Tag</td>\n",
       "      <td>In a medium saucepan over medium heat, stir to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Apam balik</td>\n",
       "      <td>Malaysian</td>\n",
       "      <td>No Tag</td>\n",
       "      <td>Mix milk, oil and egg together. Sift flour, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Beef Asado</td>\n",
       "      <td>Filipino</td>\n",
       "      <td>No Tag</td>\n",
       "      <td>Combine beef, crushed peppercorn, soy sauce, v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Meal Name     Origin                          Tags   \\\n",
       "1        Corba    Turkish                           Soup   \n",
       "2       Tamiya   Egyptian                         No Tag   \n",
       "3      Lasagne    Italian                         No Tag   \n",
       "4      Kafteji   Tunisian                         No Tag   \n",
       "5      Dal fry     Indian          Curry,Vegetarian,Cake   \n",
       "6      Big Mac   American                         No Tag   \n",
       "7      Koshari   Egyptian                         No Tag   \n",
       "8     Kapsalon      Dutch                          Snack   \n",
       "9     Stamppot      Dutch               Savory,Breakfast   \n",
       "10    Flamiche     French                           Tart   \n",
       "11    Moussaka      Greek                         No Tag   \n",
       "12    Pancakes   American  Breakfast,Desert,Sweet,Fruity   \n",
       "13    Shawarma   Egyptian                         No Tag   \n",
       "14   Shakshuka   Egyptian           Egg,Brunch,Breakfast   \n",
       "15   Yaki Udon   Japanese                     LowCalorie   \n",
       "16   Ribollita    Italian                     Vegetarian   \n",
       "17   Sugar Pie   Canadian                     Pie,Desert   \n",
       "18  Rock Cakes    British                    Baking,Cake   \n",
       "19  Pad See Ew       Thai                          Pasta   \n",
       "20  Rappie Pie   Canadian                            Pie   \n",
       "21  Ma Po Tofu    Chinese                         No Tag   \n",
       "22  Coq au vin     French                         No Tag   \n",
       "23  Nasi lemak  Malaysian                         No Tag   \n",
       "24  Apam balik  Malaysian                         No Tag   \n",
       "25  Beef Asado   Filipino                         No Tag   \n",
       "\n",
       "                                         Instructions  \n",
       "1   Pick through your lentils for any foreign debr...  \n",
       "2   oak the beans in water to cover overnight.Drai...  \n",
       "3   Heat the oil in a large saucepan. Use kitchen ...  \n",
       "4   Peel potatoes and cut into 5cm cubes.Pour 1-2 ...  \n",
       "5   Wash and soak toor dal in approx. 3 cups of wa...  \n",
       "6   For the Big Mac sauce, combine all the ingredi...  \n",
       "7   Cook the lentils. Bring lentils and 4 cups of ...  \n",
       "8   Cut the meat into strips. Heat oil in a pan an...  \n",
       "9   Wash and peel the potatoes and cut into simila...  \n",
       "10  For the pastry, sift the flour and salt into t...  \n",
       "11  Heat the grill to high. Brown the beef in a de...  \n",
       "12  Put the flour, eggs, milk, 1 tbsp oil and a pi...  \n",
       "13  Combine the marinade ingredients in a large zi...  \n",
       "14  Heat the oil in a frying pan that has a lid, t...  \n",
       "15  Boil some water in a large saucepan. Add 250ml...  \n",
       "16  Put 2 tablespoons of the oil in a large pot ov...  \n",
       "17  Preheat oven to 350 degrees F (175 degrees C)....  \n",
       "18  Preheat oven to 180C/350F/Gas 4 and line a bak...  \n",
       "19  Mix Sauce in small bowl.Mince garlic into wok ...  \n",
       "20  Preheat oven to 400 degrees F (200 degrees C)....  \n",
       "21  Add a small pinch of salt and sesame oil to mi...  \n",
       "22  Heat 1 tbsp of the oil in a large, heavy-based...  \n",
       "23  In a medium saucepan over medium heat, stir to...  \n",
       "24  Mix milk, oil and egg together. Sift flour, ba...  \n",
       "25  Combine beef, crushed peppercorn, soy sauce, v...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file = pd.read_json('food_data.json')\n",
    "data = np.array(file['meals'])\n",
    "# print(data)\n",
    "my_array = []\n",
    "for i ,row in enumerate(data):\n",
    "    my_array.append([row['strMeal'], row['strArea'],row['strTags'],row['strInstructions']])\n",
    "my_array = np.array(my_array) \n",
    "index_array = np.arange(len(my_array))\n",
    "index_array += 1 \n",
    "\n",
    "for i in range(len(my_array)):\n",
    "    my_array[:,3][i] = str(my_array[:,3][i]).replace('\\r\\n', '').replace('\\\\r\\\\n', '').replace('0.\\t', '').replace('\\t', '')\n",
    "    # my_array[:,2][i] = str(my_array[:,2][i]) + ''\n",
    "\n",
    "    # if my_array[:,2][i] is None:\n",
    "    #     my_array[:,2][i] = 'No Tag'\n",
    "\n",
    "data_dict = {\n",
    "             'Meal Name':my_array[:,0],\n",
    "             'Origin':my_array[:,1], \n",
    "             'Tags ':my_array[:,2], \n",
    "             'Instructions':my_array[:,3]\n",
    "            }\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "my_dataframe = pd.DataFrame(data_dict, index=index_array)\n",
    "my_dataframe[my_dataframe.isnull()] = 'No Tag'\n",
    "my_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbba551-6ec6-4e3a-a8f7-f467a2f3d322",
   "metadata": {},
   "source": [
    "#### UFuncs: Index Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac0df3d0-eab8-4002-a9a1-b9eedbd2aa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0   0   1   2   3   4   5   6   7   8   9\n",
      "1  10  11  12  13  14  15  16  17  18  19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random as rng\n",
    "import numpy as np\n",
    "# A = pd.Series([2, 4, 6], index=[0, 1, 2])\n",
    "# B = pd.Series([1, 3, 5], index=[1, 2, 3])\n",
    "# A.add(B,fill_value =0)\n",
    "\n",
    "\n",
    "A = pd.DataFrame(np.arange(0, 20).reshape((2,10)))\n",
    "print(A)\n",
    "# B = pd.DataFrame(np.arange(0, 10).reshape((3,3)),columns=list('BAC'))\n",
    "# print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "528f8fdc-b28f-4883-a1a1-c4f1b5b93a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     3.0\n",
       "2     3.0\n",
       "3    10.0\n",
       "4     4.0\n",
       "5     5.0\n",
       "6     6.0\n",
       "7     8.0\n",
       "8     2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "random.seed(0)\n",
    "array_a = np.random.randint(6, size=8)\n",
    "array_b = np.random.randint(6,size=7)\n",
    "series_a = pd.Series(array_a, index=[1,2,3,4,5,6,7,8])\n",
    "series_b = pd.Series(array_b, index=[1,2,3,4,5,6,7])\n",
    "series_a.add(series_b,fill_value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6f6d06-dfd7-4602-bbb6-4e32a2b84411",
   "metadata": {},
   "source": [
    "#### Handling Missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3903c099-d967-4fb2-b8df-90b4ef2bba2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# vals1 = np.array([1, None, 3, 4])  \n",
    "# vals1.sum()\n",
    "import numpy as np\n",
    "vals2 = np.array([1, np.nan, 3, 4])\n",
    "print(np.nansum(vals2))\n",
    "print(np.sum(vals2))\n",
    "# np.nansum, np.nanmax, np.nanmin  // Handling numerical missing data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c2d7f-93ce-4c77-8c29-ae1296459802",
   "metadata": {},
   "source": [
    "#### Operating on Null Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "54432ead-8745-471c-98f4-1518773abe3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    2.0\n",
       "3    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.Series([1, np.nan, 2, None])\n",
    "data[data.isnull()] = 0\n",
    "# data[data.notnull()].sum()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e1543b-8b9c-4e7b-882c-761303d39251",
   "metadata": {},
   "source": [
    "##### isnull()\n",
    "##### Generate a Boolean mask indicating missing values\n",
    "##### notnull()\n",
    "##### Opposite of isnull()\n",
    "##### dropna()\n",
    "##### Return a filtered version of the data\n",
    "##### fillna()\n",
    "##### Return a copy of the data with missing values filled or imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad53c8-fb39-48eb-8088-9bf617e3268c",
   "metadata": {},
   "source": [
    "#### Multiply Indexed Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193a96e2-38fe-47c7-9f9f-fc365b940cda",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'population' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m index \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalifornia\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2000\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalifornia\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2010\u001b[39m),(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew York\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2000\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew York\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2010\u001b[39m),\n\u001b[0;32m      5\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTexas\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2000\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTexas\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2010\u001b[39m)]\n\u001b[0;32m      7\u001b[0m populations \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m33871648\u001b[39m, \u001b[38;5;241m37253956\u001b[39m,\n\u001b[0;32m      8\u001b[0m \u001b[38;5;241m18976457\u001b[39m, \u001b[38;5;241m19378102\u001b[39m,\n\u001b[0;32m      9\u001b[0m \u001b[38;5;241m20851820\u001b[39m, \u001b[38;5;241m25145561\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m pop \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[43mpopulation\u001b[49m , index \u001b[38;5;241m=\u001b[39m index)\n\u001b[0;32m     13\u001b[0m index \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mMultiIndex\u001b[38;5;241m.\u001b[39mfrom_tuples(index)\n\u001b[0;32m     14\u001b[0m index   \n",
      "\u001b[1;31mNameError\u001b[0m: name 'population' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "index = [('California', 2000), ('California', 2010),('New York', 2000), ('New York', 2010),\n",
    "('Texas', 2000), ('Texas', 2010)]\n",
    "\n",
    "populations = [33871648, 37253956,\n",
    "18976457, 19378102,\n",
    "20851820, 25145561]\n",
    "\n",
    "pop = pd.Series(population , index = index)\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(index)\n",
    "index   \n",
    "pop = pop.reindex(pop)\n",
    "\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be3796ad-2a97-4b9a-b5d4-bbb5d92c137a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Bob</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Guido</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Sue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>HR</th>\n",
       "      <th>Temp</th>\n",
       "      <th>HR</th>\n",
       "      <th>Temp</th>\n",
       "      <th>HR</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>visit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2013</th>\n",
       "      <th>1</th>\n",
       "      <td>54.881350</td>\n",
       "      <td>71.518937</td>\n",
       "      <td>60.276338</td>\n",
       "      <td>54.488318</td>\n",
       "      <td>42.365480</td>\n",
       "      <td>64.589411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.758721</td>\n",
       "      <td>89.177300</td>\n",
       "      <td>96.366276</td>\n",
       "      <td>38.344152</td>\n",
       "      <td>79.172504</td>\n",
       "      <td>52.889492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2014</th>\n",
       "      <th>1</th>\n",
       "      <td>56.804456</td>\n",
       "      <td>92.559664</td>\n",
       "      <td>7.103606</td>\n",
       "      <td>8.712930</td>\n",
       "      <td>2.021840</td>\n",
       "      <td>83.261985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.815675</td>\n",
       "      <td>87.001215</td>\n",
       "      <td>97.861834</td>\n",
       "      <td>79.915856</td>\n",
       "      <td>46.147936</td>\n",
       "      <td>78.052918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Subject           Bob                 Guido                   Sue           \n",
       "Type               HR       Temp         HR       Temp         HR       Temp\n",
       "year visit                                                                  \n",
       "2013 1      54.881350  71.518937  60.276338  54.488318  42.365480  64.589411\n",
       "     2      43.758721  89.177300  96.366276  38.344152  79.172504  52.889492\n",
       "2014 1      56.804456  92.559664   7.103606   8.712930   2.021840  83.261985\n",
       "     2      77.815675  87.001215  97.861834  79.915856  46.147936  78.052918"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "\n",
    "index = pd.MultiIndex.from_product([[2013, 2014], [1, 2]], names=['year', 'visit'])\n",
    "columns = pd.MultiIndex.from_product([['Bob', 'Guido', 'Sue'], ['HR', 'Temp']], names=['Subject', 'Type'])\n",
    "# print(index)\n",
    "# print(columns)\n",
    "data  = np.abs(np.random.random(24)).reshape((4,6))\n",
    "data *= 100\n",
    "# data1 = pd.Series(data[:,0])\n",
    "# data2 = pd.Series(data[:,1])\n",
    "# data3 = pd.Series(data[:,2])\n",
    "# data4 = pd.Series(data[:,3])\n",
    "# data5 = pd.Series(data[:,4])\n",
    "# data6 = pd.Series(data[:,5])\n",
    "full_d = pd.DataFrame(data ,index=index, columns=columns)\n",
    "full_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86fc06f-23ab-4b4b-871c-9ac07c47e411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char  int\n",
      "a     1      0.879593\n",
      "      2      0.537158\n",
      "c     1      0.564375\n",
      "      2      0.597359\n",
      "b     1      0.981746\n",
      "      2      0.354971\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "char  int\n",
       "a     1      0.879593\n",
       "      2      0.537158\n",
       "b     1      0.981746\n",
       "      2      0.354971\n",
       "c     1      0.564375\n",
       "      2      0.597359\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "index = pd.MultiIndex.from_product([['a','c','b'], [1,2]])\n",
    "data = pd.Series(np.random.rand(6), index= index)\n",
    "data.index.names = ['char', 'int']\n",
    "print(data)\n",
    "data.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7614ab-e842-4fe0-b6fe-ddce954a6db3",
   "metadata": {},
   "source": [
    "#### Simple concatination with pd.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce8a3c4-fd2d-4f1a-91e3-7ba8e61a10e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    A\n",
       "2    B\n",
       "3    C\n",
       "4    G\n",
       "5    F\n",
       "6    E\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ser1 = pd.Series(['A','B','C'], index=[1,2,3])\n",
    "ser2 = pd.Series(['E','F','G'], index=[6,5,4])\n",
    "allser = pd.concat([ser1,ser2])\n",
    "allser.sort_index()\n",
    "# pd.merge(ser1,ser2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae07a26-8a4a-442c-869f-e69acb4dab93",
   "metadata": {},
   "source": [
    "### Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c489ff9-c47b-4dc7-857d-20e8ce64a5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>food</th>\n",
       "      <th>drink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>No food</td>\n",
       "      <td>beer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mary</td>\n",
       "      <td>bread</td>\n",
       "      <td>wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paul</td>\n",
       "      <td>beans</td>\n",
       "      <td>No drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peter</td>\n",
       "      <td>fish</td>\n",
       "      <td>No drink</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name     food     drink\n",
       "1  Joseph  No food      beer\n",
       "2    Mary    bread      wine\n",
       "3    Paul    beans  No drink\n",
       "4   Peter     fish  No drink"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df6 = pd.DataFrame({'name': ['Peter', 'Paul', 'Mary'],\n",
    "                    'food': ['fish', 'beans', 'bread']},\n",
    "                   columns=['name', 'food'] )\n",
    "\n",
    "df7 = pd.DataFrame({'name': ['Mary', 'Joseph'],\n",
    "                    'drink': ['wine', 'beer']},\n",
    "                    columns=['name', 'drink'])\n",
    "\n",
    "all_pd  = pd.merge(df6,df7 ,how = 'outer', on='name') # Outer join , inner join use (inner)\n",
    "# You can also use it based on the column. eg : (how = 'outer', on = 'name') \n",
    "\n",
    "all_pd.loc[all_pd['food'].isnull(), 'food'] = 'No food'\n",
    "all_pd.isnull().any()\n",
    "all_pd.loc[all_pd['drink'].isnull(), 'drink'] = 'No drink'\n",
    "all_pd.index  = np.arange(1, len(all_pd)+1)\n",
    "all_pd\n",
    "# all_merge = pd.merge(df6,df7, on='name' , how= 'outer') \n",
    "# all_merge"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5288e5b8-bcb2-4cd6-956f-555a201a8bb8",
   "metadata": {},
   "source": [
    "Hereâ€™s a basic example of using Invoke-WebRequest:\n",
    "\n",
    "\n",
    "Invoke-WebRequest -Uri https://example.com -OutFile example.html\n",
    "\n",
    "-Uri: Specifies the URL to send the request to.\n",
    "-OutFile: Specifies the path where the content will be saved.\n",
    "\n",
    "In this example, the content from https://example.com will be downloaded and saved as example.html in the current directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "76165391-5aa2-4065-a7b7-cbfb5b58ccdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state/region</th>\n",
       "      <th>ages</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>state</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>area (sq. mi)</th>\n",
       "      <th>Population Density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>AK</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>713868.0</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "      <td>656425.0</td>\n",
       "      <td>1.087509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>WY</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>564222.0</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>WY</td>\n",
       "      <td>97818.0</td>\n",
       "      <td>5.768079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>MT</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>990527.0</td>\n",
       "      <td>Montana</td>\n",
       "      <td>MT</td>\n",
       "      <td>147046.0</td>\n",
       "      <td>6.736171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>ND</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>674344.0</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>ND</td>\n",
       "      <td>70704.0</td>\n",
       "      <td>9.537565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>SD</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>816211.0</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>SD</td>\n",
       "      <td>77121.0</td>\n",
       "      <td>10.583512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>NM</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>2064982.0</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>NM</td>\n",
       "      <td>121593.0</td>\n",
       "      <td>16.982737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>ID</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>1570718.0</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>ID</td>\n",
       "      <td>83574.0</td>\n",
       "      <td>18.794338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>NE</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>1829838.0</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>NE</td>\n",
       "      <td>77358.0</td>\n",
       "      <td>23.654153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>NV</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>2703230.0</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>NV</td>\n",
       "      <td>110567.0</td>\n",
       "      <td>24.448796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>UT</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>2774424.0</td>\n",
       "      <td>Utah</td>\n",
       "      <td>UT</td>\n",
       "      <td>84904.0</td>\n",
       "      <td>32.677188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>KS</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>2858910.0</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>KS</td>\n",
       "      <td>82282.0</td>\n",
       "      <td>34.745266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>ME</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>1327366.0</td>\n",
       "      <td>Maine</td>\n",
       "      <td>ME</td>\n",
       "      <td>35387.0</td>\n",
       "      <td>37.509990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>OR</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>3837208.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>OR</td>\n",
       "      <td>98386.0</td>\n",
       "      <td>39.001565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>CO</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>5048196.0</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>CO</td>\n",
       "      <td>104100.0</td>\n",
       "      <td>48.493718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>OK</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>3759263.0</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>OK</td>\n",
       "      <td>69903.0</td>\n",
       "      <td>53.778278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>IA</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>3050314.0</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>IA</td>\n",
       "      <td>56276.0</td>\n",
       "      <td>54.202751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>AR</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>2922280.0</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "      <td>53182.0</td>\n",
       "      <td>54.948667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>AZ</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>6408790.0</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "      <td>114006.0</td>\n",
       "      <td>56.214497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>MN</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>5310337.0</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>86943.0</td>\n",
       "      <td>61.078373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>MS</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>2970047.0</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>MS</td>\n",
       "      <td>48434.0</td>\n",
       "      <td>61.321530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>VT</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>625793.0</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>VT</td>\n",
       "      <td>9615.0</td>\n",
       "      <td>65.085075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>WV</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>1854146.0</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>WV</td>\n",
       "      <td>24231.0</td>\n",
       "      <td>76.519582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>MO</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>5996063.0</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>MO</td>\n",
       "      <td>69709.0</td>\n",
       "      <td>86.015622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>WI</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>5689060.0</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>WI</td>\n",
       "      <td>65503.0</td>\n",
       "      <td>86.851900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>LA</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>4545392.0</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>LA</td>\n",
       "      <td>51843.0</td>\n",
       "      <td>87.676099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>AL</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>4785570.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>52423.0</td>\n",
       "      <td>91.287603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>TX</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>25245178.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>TX</td>\n",
       "      <td>268601.0</td>\n",
       "      <td>93.987655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>WA</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>6742256.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>WA</td>\n",
       "      <td>71303.0</td>\n",
       "      <td>94.557817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>MI</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>9876149.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>MI</td>\n",
       "      <td>96810.0</td>\n",
       "      <td>102.015794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>KY</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>4347698.0</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>KY</td>\n",
       "      <td>40411.0</td>\n",
       "      <td>107.586994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>HI</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>1363731.0</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>HI</td>\n",
       "      <td>10932.0</td>\n",
       "      <td>124.746707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>NH</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>1316614.0</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>NH</td>\n",
       "      <td>9351.0</td>\n",
       "      <td>140.799273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>SC</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>4636361.0</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>SC</td>\n",
       "      <td>32007.0</td>\n",
       "      <td>144.854594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>TN</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>6356683.0</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>TN</td>\n",
       "      <td>42146.0</td>\n",
       "      <td>150.825298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>GA</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>9713248.0</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>GA</td>\n",
       "      <td>59441.0</td>\n",
       "      <td>163.409902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>NC</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>9559533.0</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>NC</td>\n",
       "      <td>53821.0</td>\n",
       "      <td>177.617157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>IN</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>6489965.0</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>IN</td>\n",
       "      <td>36420.0</td>\n",
       "      <td>178.197831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>VA</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>8024417.0</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>VA</td>\n",
       "      <td>42769.0</td>\n",
       "      <td>187.622273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>IL</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>12839695.0</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>IL</td>\n",
       "      <td>57918.0</td>\n",
       "      <td>221.687472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>CA</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>37333601.0</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>163707.0</td>\n",
       "      <td>228.051342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>OH</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>11545435.0</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>OH</td>\n",
       "      <td>44828.0</td>\n",
       "      <td>257.549634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>PA</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>12710472.0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA</td>\n",
       "      <td>46058.0</td>\n",
       "      <td>275.966651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>FL</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>18846054.0</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FL</td>\n",
       "      <td>65758.0</td>\n",
       "      <td>286.597129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>NY</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>19398228.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>54475.0</td>\n",
       "      <td>356.094135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>DE</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>899711.0</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>DE</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>460.445752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>MD</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>5787193.0</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>MD</td>\n",
       "      <td>12407.0</td>\n",
       "      <td>466.445797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>MA</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>6563263.0</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>MA</td>\n",
       "      <td>10555.0</td>\n",
       "      <td>621.815538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>CT</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>3579210.0</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>CT</td>\n",
       "      <td>5544.0</td>\n",
       "      <td>645.600649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>RI</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>1052669.0</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>RI</td>\n",
       "      <td>1545.0</td>\n",
       "      <td>681.339159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>NJ</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>8802707.0</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>8722.0</td>\n",
       "      <td>1009.253268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>PR</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>3721208.0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>PR</td>\n",
       "      <td>3515.0</td>\n",
       "      <td>1058.665149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>DC</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>605125.0</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>DC</td>\n",
       "      <td>68.0</td>\n",
       "      <td>8898.897059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state/region   ages  year  population                 state abbreviation  \\\n",
       "44             AK  total  2010    713868.0                Alaska           AK   \n",
       "2502           WY  total  2010    564222.0               Wyoming           WY   \n",
       "1254           MT  total  2010    990527.0               Montana           MT   \n",
       "1350           ND  total  2010    674344.0          North Dakota           ND   \n",
       "2059           SD  total  2010    816211.0          South Dakota           SD   \n",
       "1579           NM  total  2010   2064982.0            New Mexico           NM   \n",
       "630            ID  total  2010   1570718.0                 Idaho           ID   \n",
       "1435           NE  total  2010   1829838.0              Nebraska           NE   \n",
       "1590           NV  total  2010   2703230.0                Nevada           NV   \n",
       "2214           UT  total  2010   2774424.0                  Utah           UT   \n",
       "774            KS  total  2010   2858910.0                Kansas           KS   \n",
       "1051           ME  total  2010   1327366.0                 Maine           ME   \n",
       "1819           OR  total  2010   3837208.0                Oregon           OR   \n",
       "284            CO  total  2010   5048196.0              Colorado           CO   \n",
       "1734           OK  total  2010   3759263.0              Oklahoma           OK   \n",
       "619            IA  total  2010   3050314.0                  Iowa           IA   \n",
       "142            AR  total  2010   2922280.0              Arkansas           AR   \n",
       "150            AZ  total  2010   6408790.0               Arizona           AZ   \n",
       "1147           MN  total  2010   5310337.0             Minnesota           MN   \n",
       "1206           MS  total  2010   2970047.0           Mississippi           MS   \n",
       "2347           VT  total  2010    625793.0               Vermont           VT   \n",
       "2454           WV  total  2010   1854146.0         West Virginia           WV   \n",
       "1195           MO  total  2010   5996063.0              Missouri           MO   \n",
       "2443           WI  total  2010   5689060.0             Wisconsin           WI   \n",
       "870            LA  total  2010   4545392.0             Louisiana           LA   \n",
       "52             AL  total  2010   4785570.0               Alabama           AL   \n",
       "2155           TX  total  2010  25245178.0                 Texas           TX   \n",
       "2395           WA  total  2010   6742256.0            Washington           WA   \n",
       "1062           MI  total  2010   9876149.0              Michigan           MI   \n",
       "859            KY  total  2010   4347698.0              Kentucky           KY   \n",
       "571            HI  total  2010   1363731.0                Hawaii           HI   \n",
       "1483           NH  total  2010   1316614.0         New Hampshire           NH   \n",
       "1974           SC  total  2010   4636361.0        South Carolina           SC   \n",
       "2070           TN  total  2010   6356683.0             Tennessee           TN   \n",
       "486            GA  total  2010   9713248.0               Georgia           GA   \n",
       "1339           NC  total  2010   9559533.0        North Carolina           NC   \n",
       "726            IN  total  2010   6489965.0               Indiana           IN   \n",
       "2262           VA  total  2010   8024417.0              Virginia           VA   \n",
       "715            IL  total  2010  12839695.0              Illinois           IL   \n",
       "198            CA  total  2010  37333601.0            California           CA   \n",
       "1723           OH  total  2010  11545435.0                  Ohio           OH   \n",
       "1830           PA  total  2010  12710472.0          Pennsylvania           PA   \n",
       "476            FL  total  2010  18846054.0               Florida           FL   \n",
       "1638           NY  total  2010  19398228.0              New York           NY   \n",
       "428            DE  total  2010    899711.0              Delaware           DE   \n",
       "966            MD  total  2010   5787193.0              Maryland           MD   \n",
       "955            MA  total  2010   6563263.0         Massachusetts           MA   \n",
       "294            CT  total  2010   3579210.0           Connecticut           CT   \n",
       "1963           RI  total  2010   1052669.0          Rhode Island           RI   \n",
       "1494           NJ  total  2010   8802707.0            New Jersey           NJ   \n",
       "1915           PR  total  2010   3721208.0           Puerto Rico           PR   \n",
       "342            DC  total  2010    605125.0  District of Columbia           DC   \n",
       "\n",
       "      area (sq. mi)  Population Density  \n",
       "44         656425.0            1.087509  \n",
       "2502        97818.0            5.768079  \n",
       "1254       147046.0            6.736171  \n",
       "1350        70704.0            9.537565  \n",
       "2059        77121.0           10.583512  \n",
       "1579       121593.0           16.982737  \n",
       "630         83574.0           18.794338  \n",
       "1435        77358.0           23.654153  \n",
       "1590       110567.0           24.448796  \n",
       "2214        84904.0           32.677188  \n",
       "774         82282.0           34.745266  \n",
       "1051        35387.0           37.509990  \n",
       "1819        98386.0           39.001565  \n",
       "284        104100.0           48.493718  \n",
       "1734        69903.0           53.778278  \n",
       "619         56276.0           54.202751  \n",
       "142         53182.0           54.948667  \n",
       "150        114006.0           56.214497  \n",
       "1147        86943.0           61.078373  \n",
       "1206        48434.0           61.321530  \n",
       "2347         9615.0           65.085075  \n",
       "2454        24231.0           76.519582  \n",
       "1195        69709.0           86.015622  \n",
       "2443        65503.0           86.851900  \n",
       "870         51843.0           87.676099  \n",
       "52          52423.0           91.287603  \n",
       "2155       268601.0           93.987655  \n",
       "2395        71303.0           94.557817  \n",
       "1062        96810.0          102.015794  \n",
       "859         40411.0          107.586994  \n",
       "571         10932.0          124.746707  \n",
       "1483         9351.0          140.799273  \n",
       "1974        32007.0          144.854594  \n",
       "2070        42146.0          150.825298  \n",
       "486         59441.0          163.409902  \n",
       "1339        53821.0          177.617157  \n",
       "726         36420.0          178.197831  \n",
       "2262        42769.0          187.622273  \n",
       "715         57918.0          221.687472  \n",
       "198        163707.0          228.051342  \n",
       "1723        44828.0          257.549634  \n",
       "1830        46058.0          275.966651  \n",
       "476         65758.0          286.597129  \n",
       "1638        54475.0          356.094135  \n",
       "428          1954.0          460.445752  \n",
       "966         12407.0          466.445797  \n",
       "955         10555.0          621.815538  \n",
       "294          5544.0          645.600649  \n",
       "1963         1545.0          681.339159  \n",
       "1494         8722.0         1009.253268  \n",
       "1915         3515.0         1058.665149  \n",
       "342            68.0         8898.897059  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# US STATES DATA \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "stateabv = pd.read_csv('state-abbrevs.csv')\n",
    "stateareas = pd.read_csv('state-areas.csv')\n",
    "statepop = pd.read_csv('state-population.csv')\n",
    "pd.options.mode.copy_on_write = True\n",
    "states = pd.merge(stateabv, stateareas, how = 'outer', on = 'state') \n",
    "# states[states.isnull()] = 'No Code'\n",
    "abv = states['abbreviation']\n",
    "abv[abv.isnull()] = 'None'\n",
    "states.index = np.arange(1,len(states)+1)\n",
    "\n",
    "# stateabv.head(), stateareas.head(), statepop.head()\n",
    "\n",
    "# data = pd.merge(states, statepop, how= 'outer', left_on = 'state', right_on = 'state/region')\n",
    "# data\n",
    "\n",
    "data = pd.merge(statepop,stateabv, how= 'outer', left_on = 'state/region', right_on = 'abbreviation')\n",
    "data.index = np.arange(1,len(data)+1)\n",
    "states\n",
    "\n",
    "# if data.isnull().any() is False:\n",
    "#    data[data.isnull()] = 'None'\n",
    "\n",
    "data.isnull().any()  # Checking if any data is null \n",
    "\n",
    "data[data['population'].isnull()] # Displays the null part of the data for population\n",
    "\n",
    "# data.loc[data['state'].isnull(), 'state/region'].unique()\n",
    "\n",
    "# data[data['state'].isnull()] = 'Puerto Rico'\n",
    "            \n",
    "data.loc[data['state/region'] == 'PR' , 'state' ] = 'Puerto Rico'\n",
    "data.loc[data['state/region']=='USA' , 'state'] = 'America'\n",
    "data[data['population'].isnull()]\n",
    "\n",
    "# if data['state/region'].any() == 'AK':\n",
    "#     data['state/region']  \n",
    "data.loc[data['state'] == 'America', 'state/region']\n",
    "\n",
    "data.loc[data['state/region'] == 'USA'] # Displaying all data (data) where state/region equals USA\n",
    "\n",
    "# data2000 = data.loc[data['year'] >= 2000]  \n",
    "# data2000\n",
    "# data2000.head()\n",
    "\n",
    "\n",
    "final = pd.merge(data, stateareas, on = 'state', how='left')\n",
    "final.loc[final['state/region'] == 'WY']\n",
    "final.isnull().any()\n",
    "\n",
    "final.loc[final['abbreviation'].isnull()]\n",
    "\n",
    "final.loc[final['state/region'] == 'PR', 'abbreviation'] = 'PR'\n",
    "\n",
    "final.loc[final['state/region'] == 'PR']\n",
    "\n",
    "final.loc[final['state/region'] == 'USA', 'abbreviation'] = 'USA'\n",
    "\n",
    "final.isnull().any()\n",
    "\n",
    "# Dealing with area \n",
    "final.loc[final['area (sq. mi)'].isnull(), 'state']\n",
    "final.loc[final['area (sq. mi)'].isnull()] = 0 \n",
    "final.isnull().any()\n",
    "\n",
    "#Dealing with population \n",
    "final.loc[final['population'].isnull()] = 0\n",
    "final.isnull().any()\n",
    "\n",
    "# Missing data corrected :)\n",
    "final_data = final\n",
    "\n",
    "final_data\n",
    "final_data.index = np.arange(1,len(final_data)+1)\n",
    "\n",
    "final_data.isnull().any()\n",
    "final_data['Population Density'] = final_data['population'] / final_data['area (sq. mi)']\n",
    "final_data.loc[final_data['year'] == 2010]\n",
    "\n",
    "query_data = final_data.query(\"year == 2010 & ages == 'total'\") # require numexpr to be installed  \n",
    "query_data = query_data.sort_values(by= 'Population Density')\n",
    "query_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e85d0-2b0d-41de-a8c4-729b78e03f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
